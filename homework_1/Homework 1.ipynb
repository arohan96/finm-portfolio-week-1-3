{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97c4251",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "## FINM 36700 - 2024\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu\n",
    "\n",
    "## HBS Case\n",
    "\n",
    "### *The Harvard Management Company and Inflation-Indexed Bonds*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef92ba4",
   "metadata": {},
   "source": [
    "### Notation\n",
    "(Hidden LaTeX commands)\n",
    "\n",
    "$$\\newcommand{\\mux}{\\tilde{\\boldsymbol{\\mu}}}$$\n",
    "$$\\newcommand{\\wtan}{\\boldsymbol{\\text{w}}^{\\text{tan}}}$$\n",
    "$$\\newcommand{\\wtarg}{\\boldsymbol{\\text{w}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\mutarg}{\\tilde{\\boldsymbol{\\mu}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\wEW}{\\boldsymbol{\\text{w}}^{\\text{EW}}}$$\n",
    "$$\\newcommand{\\wRP}{\\boldsymbol{\\text{w}}^{\\text{RP}}}$$\n",
    "$$\\newcommand{\\wREG}{\\boldsymbol{\\text{w}}^{\\text{REG}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb624b4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfdadc",
   "metadata": {},
   "source": [
    "# 1. HMC's Approach\n",
    "\n",
    "**Section 1 is not graded**, and you do not need to submit your answers. But you are encouraged to think about them, and we will discuss them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eafffb",
   "metadata": {},
   "source": [
    "### 1. \n",
    "There are thousands of individual risky assets in which HMC can invest.  Explain why MV optimization across 1,000 securities is infeasible.\n",
    "\n",
    "### 2.\n",
    "Rather than optimize across all securities directly, HMC runs a two-stage optimization.\n",
    "1. They build asset class portfolios with each one optimized over the securities of the specific asset class.  \n",
    "2. HMC combines the asset-class portfolios into one total optimized portfolio.\n",
    "\n",
    "In order for the two-stage optimization to be a good approximation of the full MV-optimization on all assets, what must be true of the partition of securities into asset classes?\n",
    "\n",
    "### 3.\n",
    "Should TIPS form a new asset class or be grouped into one of the other 11 classes?\n",
    "\n",
    "### 4. \n",
    "Why does HMC focus on real returns when analyzing its portfolio allocation? Is this just a matter of scaling, or does using real returns versus nominal returns potentially change the MV solution?\n",
    "\n",
    "### 5.\n",
    "The case discusses the fact that Harvard places bounds on the portfolio allocation rather than implementing whatever numbers come out of the MV optimization problem.\n",
    "\n",
    "How might we adjust the stated optimization problem in the lecture notes to reflect the extra constraints Harvard is using in their bounded solutions given in Exhibits 5 and 6?\n",
    "\n",
    "### 6. \n",
    "Exhibits 5 shows zero allocation to domestic equities and domestic bonds across the entire computed range of targeted returns, (5.75% to 7.25%). Conceptually, why is the constraint binding in all these cases? What would the unconstrained portfolio want to do with those allocations and why?\n",
    "\n",
    "### 7.\n",
    "Exhibit 6 changes the constraints, (tightening them in most cases.) How much deterioration do we see in the mean-variance tradeoff that Harvard achieved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7adf1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1614003",
   "metadata": {},
   "source": [
    "# 2 Mean-Variance Optimization\n",
    "\n",
    "<i>This section is graded for a good-faith effort by your group. Submit your write-up- along with your supporting code. </i>\n",
    "\n",
    "### Data\n",
    "You will need the file in the github repo, `data/multi_asset_etf_data.xlsx`.\n",
    "- The time-series data gives monthly returns for the 11 asset classes and a short-term Treasury-bill fund return, (\"SHV\",) which we consider as the risk-free rate.\n",
    "- The data is provided in total returns, (in which case you should ignore the SHV column,) as well as excess returns, (where SHV has been subtracted from the other columns.)\n",
    "- These are nominal returns-they are not adjusted for inflation, and in our calculations we are not making any adjustment for inflation.\n",
    "- The exhibit data that comes via Harvard with the case is unnecessary for our analysis.\n",
    "\n",
    "### Model\n",
    "We are going to analyze the problem in terms of **excess** returns.\n",
    "- Thus, you will focus on the `Excess Returns` section of the lecture notes, especially the formulas on slide 50.\n",
    "- Be sure to use the`excess returns` tab of the data.\n",
    "\n",
    "### Format\n",
    "In the questions below, **annualize the statistics** you report.\n",
    "- Annualize the mean of monthly returns with a scaling of 12.\n",
    "- Annualize the volatility of monthly returns with a scaling of $\\sqrt{12}$\n",
    "- The Sharpe Ratio is the mean return divided by the volatility of returns. Accordingly, we can annualize the Sharpe Ratio with a scaling of $\\sqrt{12}$\n",
    "- Note that we are not scaling the raw timeseries data, just the statistics computed from it (mean, vol, Sharpe). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa47172",
   "metadata": {},
   "source": [
    "### Footnotes\n",
    "\n",
    "#### Data File\n",
    "* The case does not give time-series data, so this data has been compiled outside of the case, and it intends to represent the main asset classes under consideration via various ETFs. For details on the specific securities/indexes, check the “Info” tab of the data.\n",
    "\n",
    "#### Risk-free rate\n",
    "* In the lecture-note we considered a constant risk-free rate. It is okay that our risk-free rate changes over time, but the assumption is that investors know it’s value one-period ahead of time. Thus, at any given point in time, it is a risk-free rate for the next period. (This is often discussed as the \"bank account\" or \"money market account\" in other settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3962427",
   "metadata": {},
   "source": [
    "## 1. Summary Statistics\n",
    "* Calculate and display the mean and volatility of each asset’s excess return. (Recall we use volatility to refer to standard deviation.)\n",
    "* Which assets have the best and worst Sharpe ratios? Recall that the Sharpe Ratio is simply the ratio of the mean-to-volatility of excess returns:\n",
    "$$\\text{sharpe ratio of investment }i = \\frac{\\mux_i}{\\sigma_i}$$\n",
    "\n",
    "## 2. Descriptive Analysis\n",
    "* Calculate the correlation matrix of the returns. Which pair has the highest correlation? And the lowest?\n",
    "* How well have TIPS done in our sample? Have they outperformed domestic bonds? Foreign bonds?\n",
    "\n",
    "## 3. The MV frontier.\n",
    "* Compute and display the weights of the tangency portfolios: $\\wtan$.\n",
    "* Does the ranking of weights align with the ranking of Sharpe ratios?\n",
    "* Compute the mean, volatility, and Sharpe ratio for the tangency portfolio corresponding to\n",
    "$\\wtan$.\n",
    "\n",
    "## 4. TIPS\n",
    "Assess how much the tangency portfolio (and performance) change if...\n",
    "* TIPS are dropped completely from the investment set.\n",
    "* The expected excess return to TIPS is adjusted to be 0.0012 higher than what the historic sample shows.\n",
    "\n",
    "Based on the analysis, do TIPS seem to expand the investment opportunity set, implying that Harvard should consider them as a separate asset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "272d8eec-3b48-40e2-8d3f-f3fef11575ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Excess Returns of the Assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BWX   -0.011888\n",
       "DBC   -0.009086\n",
       "EEM    0.026960\n",
       "EFA    0.055037\n",
       "HYG    0.037356\n",
       "IEF    0.013939\n",
       "IYR    0.077912\n",
       "PSP    0.092851\n",
       "QAI    0.014959\n",
       "SPY    0.126983\n",
       "TIP    0.016844\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility of Excess Returns of the Assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BWX    0.081671\n",
       "DBC    0.168455\n",
       "EEM    0.179940\n",
       "EFA    0.152203\n",
       "HYG    0.077289\n",
       "IEF    0.063197\n",
       "IYR    0.169585\n",
       "PSP    0.215238\n",
       "QAI    0.049007\n",
       "SPY    0.143066\n",
       "TIP    0.051258\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asset with highest Sharpe Ratio: SPY\n",
      "Asset with lowest Sharpe Ratio: BWX\n",
      "\n",
      "The Asset Pair with Maximum Correlation is EFA-PSP\n",
      "The Asset Pair with Minimum Correlation is DBC-IEF\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TIP    0.328618\n",
       "IEF    0.220561\n",
       "BWX   -0.145563\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIPS have outperformed both domestic and foreign bonds on a risk-adjusted basis\n",
      "\n",
      "Weights of the Tangency Portfolio:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QAI   -7.220592\n",
       "BWX   -2.730253\n",
       "IYR   -0.877108\n",
       "EFA   -0.530692\n",
       "TIP   -0.510436\n",
       "PSP   -0.277002\n",
       "DBC    0.111241\n",
       "EEM    0.615698\n",
       "HYG    0.832578\n",
       "IEF    4.682480\n",
       "SPY    4.904086\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratios:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BWX   -0.145563\n",
       "DBC   -0.053935\n",
       "EEM    0.149829\n",
       "IEF    0.220561\n",
       "QAI    0.305241\n",
       "TIP    0.328618\n",
       "EFA    0.361605\n",
       "PSP    0.431386\n",
       "IYR    0.459426\n",
       "HYG    0.483335\n",
       "SPY    0.887578\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights do not match the order of the Sharpe ratio. This is because the Sharpe ratio takes only the volatility of returns into account while the MV portfolio takes into account the correlation\n",
      "\n",
      "Mean Return of Tangency Portfolio: 52.73%\n",
      "Volatility of Tangency Portfolio: 32.85%\n",
      "Sharpe Ratio of the tangency portfolio: 1.6050367396027652\n",
      "\n",
      "Reanalyzing w/o TIPS\n",
      "Weights of the Tangency Portfolio:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QAI   -7.976911\n",
       "BWX   -3.015911\n",
       "IYR   -0.990156\n",
       "EFA   -0.540606\n",
       "PSP   -0.324898\n",
       "DBC    0.090968\n",
       "EEM    0.664230\n",
       "HYG    0.871637\n",
       "IEF    4.832385\n",
       "SPY    5.389260\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratios:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BWX   -0.145563\n",
       "DBC   -0.053935\n",
       "EEM    0.149829\n",
       "IEF    0.220561\n",
       "QAI    0.305241\n",
       "TIP    0.328618\n",
       "EFA    0.361605\n",
       "PSP    0.431386\n",
       "IYR    0.459426\n",
       "HYG    0.483335\n",
       "SPY    0.887578\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights do not match the order of the Sharpe ratio. This is because the Sharpe ratio takes only the volatility of returns into account while the MV portfolio takes into account the correlation\n",
      "\n",
      "Mean Return of Tangency Portfolio: 58.08%\n",
      "Volatility of Tangency Portfolio: 36.21%\n",
      "Sharpe Ratio of the tangency portfolio: 1.603881450984104\n",
      "\n",
      "Re-analyzing with higher expected returns for TIPS\n",
      "Weights of the Tangency Portfolio:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QAI   -7.819229\n",
       "BWX   -2.956355\n",
       "IYR   -0.966587\n",
       "EFA   -0.538539\n",
       "PSP   -0.314912\n",
       "TIP   -0.106419\n",
       "DBC    0.095195\n",
       "EEM    0.654112\n",
       "HYG    0.863494\n",
       "IEF    4.801132\n",
       "SPY    5.288108\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratios:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BWX   -0.145563\n",
       "DBC   -0.053935\n",
       "EEM    0.149829\n",
       "IEF    0.220561\n",
       "QAI    0.305241\n",
       "TIP    0.328618\n",
       "EFA    0.361605\n",
       "PSP    0.431386\n",
       "IYR    0.459426\n",
       "HYG    0.483335\n",
       "SPY    0.887578\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights do not match the order of the Sharpe ratio. This is because the Sharpe ratio takes only the volatility of returns into account while the MV portfolio takes into account the correlation\n",
      "\n",
      "Mean Return of Tangency Portfolio: 56.96%\n",
      "Volatility of Tangency Portfolio: 35.51%\n",
      "Sharpe Ratio of the tangency portfolio: 1.6042840370500056\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "excess_returns_df = pd.read_excel(r'/Users/arohansharma/Desktop/assignments/finm-portfolio-2024/data/multi_asset_etf_data.xlsx', \n",
    "                                  sheet_name='excess returns', header=0, index_col=0)\n",
    "\n",
    "# Q.1a Display mean and vol\n",
    "print('Mean Excess Returns of the Assets')\n",
    "display(excess_returns_df.mean()*12)\n",
    "print('Volatility of Excess Returns of the Assets')\n",
    "display(excess_returns_df.std()*(12**0.5))\n",
    "# Q.1b Sharpe-Ratio\n",
    "sharpe_ratios = (excess_returns_df.mean()*12)/(excess_returns_df.std()*(12**0.5))\n",
    "sharpe_ratios = sharpe_ratios.sort_values()\n",
    "print('')\n",
    "print('Asset with highest Sharpe Ratio:', sharpe_ratios.index[-1])\n",
    "print('Asset with lowest Sharpe Ratio:', sharpe_ratios.index[0])\n",
    "print('')\n",
    "\n",
    "# Q.2a Correlation Matrix and Highest and Lowest Correlation\n",
    "corr_matrix = excess_returns_df.corr()\n",
    "a = np.matrix((corr_matrix.replace(to_replace=1, value=-np.inf)))\n",
    "max_corr_idx = np.unravel_index(np.argmax(a, axis=None), a.shape)\n",
    "print(f'The Asset Pair with Maximum Correlation is {corr_matrix.index[max_corr_idx[0]]}-{corr_matrix.columns[max_corr_idx[1]]}')\n",
    "a = np.matrix((corr_matrix.replace(to_replace=1, value=np.inf)))\n",
    "min_corr_idx = np.unravel_index(np.argmin(a, axis=None), a.shape)\n",
    "print(f'The Asset Pair with Minimum Correlation is {corr_matrix.index[min_corr_idx[0]]}-{corr_matrix.columns[min_corr_idx[1]]}')\n",
    "print('')\n",
    "# Q.2b\n",
    "display(sharpe_ratios[['TIP', 'IEF', 'BWX']])\n",
    "print('TIPS have outperformed both domestic and foreign bonds on a risk-adjusted basis')\n",
    "print('')\n",
    "\n",
    "# Q.3a Find weights of the tangency portfolio\n",
    "cov_matrix = excess_returns_df.cov()\n",
    "w_tan = (np.linalg.inv(np.array(cov_matrix)))*((np.matrix(excess_returns_df.mean())).T)\n",
    "w_tan = w_tan/abs(w_tan.sum())\n",
    "w_tan = pd.Series(w_tan.T.tolist()[0], index=excess_returns_df.columns)\n",
    "print('Weights of the Tangency Portfolio:')\n",
    "display(w_tan.sort_values())\n",
    "# Q.3b do the weights match the order of Sharpe?\n",
    "print('Sharpe Ratios:')\n",
    "display(sharpe_ratios)\n",
    "print('The weights do not match the order of the Sharpe ratio exactly. This is because the Sharpe ratio takes only the volatility of returns into account while the MV portfolio takes into account the correlation. However, assets with a higher sharpe will tend to have a higher weight')\n",
    "mean_return = np.matrix(w_tan)*(np.matrix(excess_returns_df.mean())).T\n",
    "print('')\n",
    "print(f'Mean Return of Tangency Portfolio: {round(mean_return[0,0]*12*100, 2)}%')\n",
    "volatility = np.matrix(w_tan)*np.matrix(cov_matrix)*np.matrix(w_tan).T\n",
    "volatility =(volatility[0,0])**0.5\n",
    "print(f'Volatility of Tangency Portfolio: {round(volatility*(12**0.5)*100, 2)}%')\n",
    "sharpe_ratio = (mean_return*12)/(volatility*(12**0.5))\n",
    "print(f'Sharpe Ratio of the tangency portfolio: {sharpe_ratio[0,0]}')\n",
    "print('')\n",
    "\n",
    "# Q.4a Re-assess without TIPS\n",
    "excess_returns_wo_tips = excess_returns_df[excess_returns_df.columns[:-1]]\n",
    "cov_matrix_wo_tips = excess_returns_wo_tips.cov()\n",
    "w_tan_wo_tips = np.linalg.inv(np.array(cov_matrix_wo_tips))*(np.matrix(excess_returns_wo_tips.mean())).T\n",
    "w_tan_wo_tips = w_tan_wo_tips/abs(w_tan_wo_tips.sum())\n",
    "w_tan_wo_tips = pd.Series(w_tan_wo_tips.T.tolist()[0], index=excess_returns_wo_tips.columns)\n",
    "print('Reanalyzing w/o TIPS')\n",
    "print('Weights of the Tangency Portfolio:')\n",
    "display(w_tan_wo_tips.sort_values())\n",
    "print('Sharpe Ratios:')\n",
    "display(sharpe_ratios)\n",
    "mean_return = np.matrix(w_tan_wo_tips)*(np.matrix(excess_returns_wo_tips.mean())).T\n",
    "print('')\n",
    "print(f'Mean Return of Tangency Portfolio: {round(mean_return[0,0]*12*100, 2)}%')\n",
    "volatility = np.matrix(w_tan_wo_tips)*np.matrix(cov_matrix_wo_tips)*np.matrix(w_tan_wo_tips).T\n",
    "volatility =(volatility[0,0])**0.5\n",
    "print(f'Volatility of Tangency Portfolio: {round(volatility*(12**0.5)*100, 2)}%')\n",
    "sharpe_ratio = (mean_return*12)/(volatility*(12**0.5))\n",
    "print(f'Sharpe Ratio of the tangency portfolio: {sharpe_ratio[0,0]}')\n",
    "print('')\n",
    "\n",
    "# Q.4b Re-assess with higher expected returns for TIPS\n",
    "print('Re-analyzing with higher expected returns for TIPS')\n",
    "cov_matrix = excess_returns_df.cov()\n",
    "mean_returns = excess_returns_df.mean()\n",
    "mean_returns.loc['TIP'] += 0.0012/12\n",
    "w_tan_w_tips_adj = np.linalg.inv(np.array(cov_matrix))*(np.matrix(mean_returns)).T\n",
    "w_tan_w_tips_adj = w_tan_w_tips_adj/abs(w_tan_w_tips_adj.sum())\n",
    "w_tan_w_tips_adj = pd.Series(w_tan_w_tips_adj.T.tolist()[0], index=excess_returns_df.columns)\n",
    "print('Weights of the Tangency Portfolio:')\n",
    "display(w_tan_w_tips_adj.sort_values())\n",
    "print('Sharpe Ratios:')\n",
    "display(sharpe_ratios)\n",
    "print('')\n",
    "print(f'Mean Return of Tangency Portfolio: {round(mean_return[0,0]*12*100, 2)}%')\n",
    "volatility = np.matrix(w_tan_w_tips_adj)*np.matrix(cov_matrix)*np.matrix(w_tan_w_tips_adj).T\n",
    "volatility =(volatility[0,0])**0.5\n",
    "print(f'Volatility of Tangency Portfolio: {round(volatility*(12**0.5)*100, 2)}%')\n",
    "sharpe_ratio = (mean_return*12)/(volatility*(12**0.5))\n",
    "print(f'Sharpe Ratio of the tangency portfolio: {sharpe_ratio[0,0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8609d16",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59490d8",
   "metadata": {},
   "source": [
    "# 3. Allocations\n",
    "\n",
    "<i>This section is graded for a good-faith effort by your group. Submit your write-up- along with your supporting code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5eb238",
   "metadata": {},
   "source": [
    "* Continue with the same data file as the previous section.\n",
    "\n",
    "* Suppose the investor has a targeted mean excess return (per month) of $\\mutarg$ = 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46b44c",
   "metadata": {},
   "source": [
    "Build the following portfolios:\n",
    "\n",
    "#### Equally-weighted (EW)\n",
    "Rescale the entire weighting vector to have target mean $\\mutarg$. Thus, the $i$ element of the weight vector is,\n",
    "$$\\wEW_i = \\frac{1}{n}$$\n",
    "\n",
    "#### “Risk-parity” (RP)\n",
    "Risk-parity is a term used in a variety of ways, but here we have in mind setting the weight of the portfolio to be proportional to the inverse of its full-sample variance estimate. Thus, the $i$ element of the weight vector is,\n",
    "$$\\wRP_i = \\frac{1}{\\sigma_i^2}$$\n",
    "\n",
    "#### Regularized (REG)\n",
    "Much like the Mean-Variance portfolio, set the weights proportional to \n",
    "$$\\wREG \\sim \\widehat{\\Sigma}^{-1}\\mux$$\n",
    "but this time, use a regularized covariance matrix,\n",
    "$$\\widehat{\\Sigma} = \\frac{\\Sigma + \\Sigma_D}{2}$$\n",
    "where $\\Sigma_D$ denotes a *diagonal* matrix of the security variances, with zeros in the off-diagonals.\n",
    "\n",
    "Thus, $\\widehat{\\Sigma}$ is obtained from the usual covariance matrix, $\\Sigma$, but shrinking all the covariances to half their estimated values. \n",
    "\n",
    "\n",
    "### Comparing\n",
    "\n",
    "In order to compare all these allocation methods, (those above, along with the tangency portfolio obtained in the previous section,) rescale each weight vector, such that it has targeted mean return of $\\mutarg$.\n",
    "\n",
    "* Calculate the performance of each of these portfolios over the sample.\n",
    "* Report their mean, volatility, and Sharpe ratio. \n",
    "* How do these compare across the four allocation methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e7d2431-96db-405d-8651-3b73ce28cdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Vol</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tangency</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.074765</td>\n",
       "      <td>1.605037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.291527</td>\n",
       "      <td>0.411625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk_parity</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.309515</td>\n",
       "      <td>0.387703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularized</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.118010</td>\n",
       "      <td>1.016864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mean       Vol    Sharpe\n",
       "tangency     0.12  0.074765  1.605037\n",
       "equal        0.12  0.291527  0.411625\n",
       "risk_parity  0.12  0.309515  0.387703\n",
       "regularized  0.12  0.118010  1.016864"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amongst the four allocations, the tangency portfolio has the highest Sharpe and lowest Vol (as expected) followed by the regularized weighting scheme. The risk parity weighted portfolio has the highest vol and the lowest Sharpe\n"
     ]
    }
   ],
   "source": [
    "def summary_statistics_annualized(returns, annual_factor = 12):\n",
    "    \"\"\"This functions returns the summary statistics for the input total/excess returns passed\n",
    "    into the function\"\"\"\n",
    "    \n",
    "    summary_statistics = pd.DataFrame(index=returns.columns)\n",
    "    summary_statistics['Mean'] = returns.mean() * annual_factor\n",
    "    summary_statistics['Vol'] = returns.std() * np.sqrt(annual_factor)\n",
    "    summary_statistics['Sharpe'] = (returns.mean() / returns.std()) * np.sqrt(annual_factor)\n",
    "    \n",
    "    return summary_statistics\n",
    "\n",
    "target_mean = 0.01\n",
    "\n",
    "w_eq = [1/len(excess_returns_df.columns)]*len(excess_returns_df.columns)\n",
    "w_rp = list(1/np.array(excess_returns_df.var()))\n",
    "cov_reg = (excess_returns_df.cov()/2 + np.diag(excess_returns_df.var()))/2\n",
    "w_reg = np.linalg.inv(cov_reg)*(np.matrix(excess_returns_df.mean())).T\n",
    "\n",
    "weights_df = pd.DataFrame(columns=['tangency', 'equal', 'risk_parity', 'regularized'])\n",
    "weights_df['tangency'] = w_tan\n",
    "weights_df['equal'] = w_eq\n",
    "weights_df['risk_parity'] = w_rp\n",
    "weights_df['regularized'] = w_reg\n",
    "weights_df.index = excess_returns_df.columns\n",
    "weights_df.fillna(0, inplace=True)\n",
    "weights_df\n",
    "\n",
    "weights_df *= target_mean / (excess_returns_df.mean()@weights_df)\n",
    "\n",
    "display(summary_statistics_annualized(excess_returns_df@weights_df))\n",
    "\n",
    "print(\"Amongst the four allocations, the tangency portfolio has the highest Sharpe and lowest Vol (as expected) followed by the regularized weighting scheme. The risk parity weighted portfolio has the highest vol and the lowest Sharpe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea828b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8443d",
   "metadata": {},
   "source": [
    "# 4. Out-of-Sample Performance\n",
    "\n",
    "<i>This section is not graded, and you do not need to submit it. Still, we may discuss it in class, in which case, you would be expected to know it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4b25b",
   "metadata": {},
   "source": [
    "## 1. One-step Out-of-Sample (OOS) Performance\n",
    "Let’s divide the sample to both compute a portfolio and then check its performance out of sample.\n",
    "* Using only data through the end of `2022`, compute the weights built in Section 3.\n",
    "* Rescale the weights, (using just the in-sample data,) to set each allocation to have the same mean return of $\\mutarg$.\n",
    "* Using those weights, calculate the portfolio’s Sharpe ratio within that sample.\n",
    "* Again using those weights, (derived using data through `2022`,) calculate the portfolio’s OOS Sharpe ratio, which is based only on performance in `2023-2024`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281c023",
   "metadata": {},
   "source": [
    "## 2. Rolling OOS Performance\n",
    "\n",
    "Iterate the Out-of-Sample performance every year, not just the final year. Namely,\n",
    "* Start at the end of `2015`, and calculate the weights through that time. Rescale them using the mean returns through that time.\n",
    "* Apply the weights to the returns in the upcoming year, (`2016`.)\n",
    "* Step forward a year in time, and recompute.\n",
    "* Continue until again calculating the weights through `2023` and applying them to the returns in `2024`.\n",
    "\n",
    "Report the mean, volatility, and Sharpe from this dynamic approach for the following portfolios:\n",
    "* mean-variance (tangency)\n",
    "* equally-weighted\n",
    "* risk-parity\n",
    "* regularized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc96f3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b0cf7",
   "metadata": {},
   "source": [
    "# 5. Without a Riskless Asset\n",
    "\n",
    "<i>This section is not graded, and you do not need to submit it. Still, we may discuss it in class, in which case, you would be expected to know it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1ff49",
   "metadata": {},
   "source": [
    "Re-do Section 2 above, but in the model without a risk-free rate.\n",
    "\n",
    "That is, build the MV allocation using the two-part formula in the `Mean-Variance` section of the notes.\n",
    "* This essentially substitutes the risk-free rate with the minimum-variance portfolio.\n",
    "* Now, the allocation depends nonlinearly on the target mean return, $\\mutarg$. (With a risk-free rate, we simply scale the weights up and down to achieve the mean return.)\n",
    "\n",
    "You will find that, conceptually, the answers are very similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5734f",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
